{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43122c35",
   "metadata": {},
   "source": [
    "# Model Evaluation: BLEU Score\n",
    "This notebook evaluates your trained transformer model using the BLEU score, a standard metric for translation quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import get_config, get_weights_path\n",
    "from train import get_model, get_dataset, greedy_decode\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23afb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up device and load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_dataset(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "model_filename = get_weights_path(config, str(config['num_epochs']))\n",
    "state = torch.load(model_filename, map_location=device)\n",
    "model.load_state_dict(state['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9867dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(model, dataloader, tokenizer_src, tokenizer_tgt, config, device, num_batches=100):\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            encoder_input = batch['encoder_input'].to(device)\n",
    "            encoder_mask = batch['encoder_mask'].to(device)\n",
    "            tgt_text = batch['tgt_text'][0]\n",
    "            model_output = greedy_decode(model, encoder_input, encoder_mask, tokenizer_src, tokenizer_tgt, config['seq_len'], device)\n",
    "            pred = tokenizer_tgt.decode(model_output.cpu().numpy())\n",
    "            references.append([tgt_text])\n",
    "            hypotheses.append(pred)\n",
    "    bleu = sacrebleu.corpus_bleu(hypotheses, list(zip(*references)))\n",
    "    print(f'BLEU score: {bleu.score:.2f}')\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdac732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BLEU score on validation set\n",
    "compute_bleu(model, val_dataloader, tokenizer_src, tokenizer_tgt, config, device, num_batches=100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
